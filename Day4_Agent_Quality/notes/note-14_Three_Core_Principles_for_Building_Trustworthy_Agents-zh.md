### 🎙️ 第 14 頁：Three_Core_Principles_for_Building_Trustworthy_Agents

#### 【本頁重點摘要】
*   **原則一：評估是架構，不是終點**。品質必須從一開始就內建於系統設計中，而非事後才測試。
*   **原則二：決策軌跡才是真相**。要真正理解 Agent 的品質，必須檢視其完整的「思考過程」，而不僅是最終答案。
*   **原則三：人類是最終的仲裁者**。自動化工具提供規模，但「好」的標準與價值判斷，最終必須由人類來定義。

---

#### 【逐字講稿】

(開場白)
好的，在我們深入探討了評估的「是什麼」與「如何做」之後，現在讓我們退一步，提煉出三個最核心、最根本的指導原則。如果你希望從今天的分享中只帶走幾件事，我希望就是這三條。它們是建立可靠、值得信賴的 AI Agent 的基石。

##### ① 第一個原則：將評估視為架構支柱，而不是最後一個步驟。

這可能是最重要的心態轉變。我們在第一章提到過那個一級方程式賽車的比喻，對吧？你不可能先把賽車造好，最後才想著「喔，我們應該加幾個感測器」。不，頂級的賽車從設計之初，每一個零件都考慮了數據遙測。

> 可靠的 Agent 是「為評估而生」(evaluable-by-design) 的。品質是一種架構選擇，而不是最後的品保階段。

從你寫下第一行程式碼開始，就要思考如何讓這個 Agent 的行為變得可觀察、可評估。這意味著，日誌、追蹤這些能力，都必須是系統內建的核心功能。

##### ② 第二個原則：決策軌跡才是真相。

對於 Agent 來說，它給你的最終答案，只是一個漫長故事的最後一句話。真正的品質、邏輯、安全性和效率，都藏在它從頭到尾的「思考過程」——也就是我們所說的「軌跡」(Trajectory) 之中。

> 要真正理解一個 Agent 為何成功或失敗，你必須分析它的完整路徑。

只看結果，你可能知道「答案錯了」，但你永遠不會知道「為什麼錯」。是因為它一開始的計畫就錯了？還是它誤解了某個工具的回傳結果？只有透過我們在第三章談到的深度「可觀察性」實踐，去檢視完整的軌跡，你才能找到問題的根源。

##### ③ 第三個原則：人類是最終的仲裁者。

自動化是我們擴展規模的工具，但人性，才是我們判斷真理的源頭。我們可以、也應該使用像 LLM-as-a-Judge 這樣的 AI 系統來進行大規模的評估，這非常有效率。

> 然而，對於「好」的根本定義、對於細膩的價值判斷、對於安全與公平的最終裁決，都必須錨定在人類的價值觀上。

一個 AI 可以幫我們批改考卷，但只有身為人類的我們，才能寫出評分標準，並定義什麼樣的答案才真正稱得上是「A+」。自動化是幫手，但人類永遠是那個決定方向的船長。

---

#### 【講者提示 & 轉場】
*   **節奏提醒**：講完這三點後，可以停頓幾秒鐘。這三個原則是整份白皮書的精髓，給聽眾一點時間吸收和思考。
*   **補充案例**：可以再次強調：「記住，我們不是在檢查一個計算機，我們是在評估一個『員工』。你會只看他交上來的報告，還是會關心他如何完成工作的？」
*   **轉場橋樑 (Bridge)**：
    > 總結來說，這三大原則——將評估視為架構、將軌跡視為真相、並以人為本——共同構成了我們建立信任的藍圖。那麼，當我們掌握了這些心法後，我們將迎來一個什麼樣的未來？下一頁，讓我們一起展望這個由可靠 Agent 所構成的新時代。