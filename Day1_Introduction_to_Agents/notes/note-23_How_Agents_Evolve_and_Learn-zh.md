### 🎙️ 第 23 頁：How_Agents_Evolve_and_Learn

#### 【本頁重點摘要】
*   為了避免效能衰退或「老化 (aging)」，AI 代理人必須被設計成能夠自主學習與適應。
*   學習的來源主要有二：一是來自運作時的經驗，特別是人類的回饋 (HITL)；二是來自外部訊號，如新的政策文件。
*   適應的方式包括：優化上下文工程 (如改善提示) 以及動態地創造或改進工具。

---

#### 【逐字講稿】

(開場白)
好，我們已經建立了一個強大的代理人，但工作還沒有結束。事實上，一個代理人被部署的那一刻，就是它開始「老化」的第一天。如果我們不為它設計學習與進化的能力，它很快就會過時。

> 在真實世界中運作的代理人，面對的是一個政策、技術和數據格式不斷變化的動態環境。如果沒有適應能力，代理人的表現將隨著時間推移而下降——這個過程通常被稱為「老化 (aging)」——最終導致其效用和信任度的喪失。

那麼，我們該如何讓代理人保持年輕、持續進化呢？答案在於賦予它們學習的能力。

##### ① 學習的來源：經驗與訊號

代理人主要透過兩種方式來學習。

第一種是 **運行時的經驗 (Runtime Experience)**。這就像人類從工作中學習一樣。代理人會從它的工作記錄中學習，比如會話日誌、追蹤數據，以及它自己的記憶。但其中最關鍵、最有價值的，就是來自 **人類在環 (Human-in-the-Loop)** 的直接回饋。當一個人類專家介入並修正代理人的行為時，這就成了一個權威性的指導，告訴代理人「下次應該這樣做」。

第二種是 **外部訊號 (External Signals)**。這包括了公司發布的新政策、政府更新的法規指南，甚至是來自其他代理人的批評與建議。這些都是讓代理人與時俱進的重要資訊來源。

##### ② 適應的技術：優化與創造

學到了新知識後，代理人需要將其轉化為行動。這主要透過兩種技術來實現。

第一種是 **強化上下文工程 (Enhanced Context Engineering)**。系統會持續地優化它提供給大腦（也就是語言模型）的資訊，比如改善提示詞、更新小樣本範例，或是從記憶中檢索更精準的資訊，從而提高下一次任務的成功率。

第二種，也是更強大的一種，是 **工具的優化與創造 (Tool Optimization and Creation)**。這代表代理人能夠意識到自己能力的不足，並主動去彌補。例如，它可能會發現自己需要一個特定的 Python 腳本來完成計算，於是它就 **即時地** 創建並執行這個腳本。這讓代理人從一個工具使用者，進化成了一個工具創造者。

##### ③ 實戰案例：懂得新規範的合規代理人

讓我們來看一個具體的例子。想像在一個像金融或生命科學這樣受到嚴格監管的行業，我們有一個代理人團隊負責生成報告。

這個團隊裡有一位 **報告代理人 (Reporting Agent)** 負責撰寫報告草稿，還有一位 **批判代理人 (Critiquing Agent)** 負責根據已知的合規指南來審查報告。

有一天，批判代理人發現一份報告的內容有點模糊，不確定是否符合最新的隱私規定，於是它將這個問題 **升級** 給一位人類專家。專家審查後指出：「根據新規定，所有關於家庭統計的數據都必須匿名化處理。」

這時，團隊裡的 **學習代理人 (Learning Agent)** 就會觀察到這次互動，並將人類專家的這個修正，轉化為一條新的、可重複使用的規則。

下一次，當報告代理人再寫出類似的報告時，批判代理人就會自動應用這條「匿名化」的新規則，不再需要人類的介入。透過這個「批判、人類回饋、歸納學習」的循環，整個系統就自主地適應了不斷變化的合規要求。

---

#### 【講者提示 & 轉場】
*   **節奏提醒**：在講完「老化 (aging)」這個概念後，可以稍微停頓一下，讓聽眾思考一下這個問題的嚴重性。
*   **補充案例**：可以提到，除了這兩種適應技術，學術界也正在積極研究更進階的方法，例如從人類回饋中進行強化學習 (RLHF)，或是動態地重組多代理人系統的設計模式。
*   **轉場橋樑 (Bridge)**：
    > 這種在職學習非常強大，但如果我們能在一個專門的、安全的環境中加速這種進化過程呢？這就帶我們進入了下一個前沿領域：模擬環境與「代理人健身房 (Agent Gym)」。