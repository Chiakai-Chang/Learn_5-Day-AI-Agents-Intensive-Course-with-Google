### 🎙️ 第 20 頁：確保單一代理程式的安全性：信任的權衡

#### 【本頁重點摘要】
*   建立代理程式存在一個根本性的矛盾：賦予它的能力（Utility）越強，潛在的安全風險就越高。
*   主要風險有兩大類：執行惡意或非預期的「流氓行為」（Rogue Actions），以及洩漏敏感資料。
*   最佳實踐是採用「深度防禦」策略，結合兩種防護層：
    1.  **確定性護欄**：寫死的、不可逾越的規則。
    2.  **基於推理的防禦**：利用 AI 來監督 AI 的行為。

---

#### 【逐字講稿】

(開場白)
各位，當我們開始打造第一個 AI 代理程式時，我們馬上會面臨一個非常核心的矛盾，那就是「功能」與「安全」之間的權衡。

為了讓代理程式有用，我們必須賦予它權力——讓它能自主做決定，使用工具去發送郵件、查詢資料庫。但我們每給予一分權力，就引入了相對應的一分風險。

> 這就像是給代理程式一條牽繩，我們希望繩子夠長，讓它能完成任務，但又必須夠短，確保它不會失控衝到馬路上——特別是當這條「馬路」涉及到不可逆轉的操作，或是公司的核心機密資料時。

那麼，具體來說，風險是什麼？我們又該如何管理呢？

##### ① 第一個挑戰：主要的資安風險

我們主要擔心兩件事：

*   第一，是**流氓行為 (Rogue Actions)**。也就是代理程式執行了我們不希望它做的、甚至是惡意的行為。
*   第二，是**資料洩漏 (Data Disclosure)**。也就是它在不經意間，洩漏了公司的敏感資訊或客戶的隱私。

這裡最關鍵的一點是，我們**不能完全依賴 AI 模型自身的判斷力**。因為模型可能會被一種叫做「提示詞注入 (Prompt Injection)」的技術所操控。所以，單純地告訴模型「要乖乖的」是絕對不夠的。

##### ② 第二個關鍵：深度防禦 (Defense-in-Depth)

既然不能只靠模型，我們就必須建立一個多層次的「深度防禦」系統。這就像蓋城堡一樣，不能只有一道城牆。

*   **第一層防禦，是「確定性護欄 (Deterministic Guardrails)」**。
    > 這些是我們寫死的、硬編碼的規則，它們在模型推理的範圍之外，形成一個絕對的安全關卡。

    舉個例子，我們可以設定一條規則：「任何超過 100 美元的採購，都必須被阻擋」，或者「在代理程式呼叫外部 API 之前，必須跳出視窗，取得真人的明確批准」。這一層提供了可預測、可審計的硬性限制。

*   **第二層防禦，是「基於推理的防禦 (Reasoning-Based Defenses)」**。
    這很有趣，它的核心思想是「用 AI 來保護 AI」。我們會部署一些小而專精的「守衛模型 (Guard Models)」，它們就像團隊裡的資安分析師。在主要代理程式執行任何計畫之前，這些守衛模型會先審查它的計畫，如果發現任何有風險或違反政策的步驟，就會立刻舉手示警。

總結來說，這種結合了**程式碼的剛性確定性**與 **AI 的情境感知能力**的混合模式，為我們的代理程式打造了一個強大的安全基礎，確保它的強大能力，始終與我們的目標保持一致。

---

#### 【講者提示 & 轉場】
*   **節奏提醒**：在講完「牽繩」這個比喻後，可以稍微停頓一下，讓聽眾消化這個概念。這個比喻非常直觀，能有效傳達核心矛盾。
*   **補充案例**：可以強調「守衛模型」就像是另一個代理程式，它的唯一工作就是監督主代理程式，這有助於引出下一頁「多代理程式」的概念。
*   **轉場橋樑 (Bridge)**：
    > 好的，我們剛剛討論了如何為「單一」代理程式建立內部的安全護欄。但如果我們公司裡有數十個、數百個代理程式呢？我們該如何管理誰能存取什麼？這就引出了下一個至關重要的議題：代理程式的「身份識別」與「政策執行」。