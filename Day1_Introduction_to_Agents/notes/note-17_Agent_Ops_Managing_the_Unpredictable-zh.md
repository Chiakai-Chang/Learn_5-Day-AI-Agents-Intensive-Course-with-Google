### 🎙️ 第 17 頁：Agent_Ops_Managing_the_Unpredictable

#### 【本頁重點摘要】
*   Agent Ops 是一套全新的營運哲學，專為管理具備隨機性、非確定性行為的 AI Agents 而設計，是 DevOps 和 MLOps 的自然演進。
*   傳統軟體的「輸出等於預期」的單元測試模式，對 Agents 而言完全不適用，因為它們的回應本質上是機率性的。
*   評估重點必須從簡單的「通過/失敗」轉向整體的「品質」評估，這通常需要借助另一個強大的語言模型（LM）來擔任「裁判」的角色。

---

#### 【逐字講稿】

(開場白)
好，各位。當你打造出第一個 Agent 時，那種興奮感是無與倫比的。但接著，你開始進入測試階段...然後你會發現自己不斷地、一遍又一遍地手動測試它的行為。當你修好一個 bug，是不是又引發了另一個問題？這就是傳統開發模式在面對 Agent 時遇到的第一個巨大挑戰。

##### ① 傳統測試的失靈
我們正經歷一場從傳統「確定性軟體 (deterministic software)」到新型「隨機性系統 (stochastic systems)」的轉變。在傳統世界裡，測試很單純，我們寫一個單元測試，然後斷言 `output == expected`。輸出必須精確地等於預期，這是一個非黑即白的結果。

但這個模式在 Agent 面前徹底崩潰了。Agent 的回應在本質上是「機率性」的。它可能用五種不同的說法，給出五個完全正確的答案。你該如何為這種情況編寫測試呢？答案是，你沒辦法。

> 我們需要一套全新的營運哲學，來應對這個充滿不確定性的新現實。

##### ② Agent Ops：從 DevOps 到新典範
這就是 **Agent Ops** 登場的時刻。你可以將它視為我們所熟悉的 DevOps 和 MLOps 的自然演進，但它專為治理、部署和建構 AI Agents 的獨特挑戰而量身打造。

最大的轉變，就是我們不再追求單純的「通過或失敗」。因為語言是複雜的，一個好的回應不僅僅是「正確」，它還必須符合我們的「品質」要求。這個 Agent 的回答，是否完成了所有該做的事？是否避免了所有不該做的事？它的語氣是否恰當？

##### ③ 以 AI 裁判 AI：LM 即裁判
為了解決這個問題，我們引入了一個非常有趣的概念：「LM as a Judge」，也就是讓一個語言模型來擔任裁判。我們使用一個強大的模型，根據預先定義好的評分標準（rubric），來自動評估我們 Agent 的輸出品質。

這套方法，就是 Agent Ops 的核心。它提供了一套有紀律、有結構的方法，來管理這種全新的不確定性。它最終的目標，是將「不可預測性」這個看似負債的特性，轉化為一個可以被管理、被衡量、而且最終值得信賴的強大功能。

---

#### 【講者提示 & 轉場】
*   **節奏提醒**：在講完「傳統測試的失靈」後，可以稍微停頓一下，讓聽眾思考這個問題的棘手之處，然後再引出 Agent Ops 這個解決方案。
*   **補充案例**：你可以用一個比喻：傳統測試就像「百米賽跑」，只看誰先到終點；而 Agent Ops 則像「體操比賽」，需要裁判根據一套複雜的規則，從執行、風格、難度等多個維度來打分，評估的是整體的「品質」。
*   **轉場橋樑 (Bridge)**：
    > 了解了我們需要一套新的哲學，以及「用 AI 評估 AI」的核心思想後，下一個問題自然就是：具體該怎麼做？我們該衡量哪些指標？開發流程該如何調整？下一頁，我們將深入探討 Agent Ops 的具體實踐方法，從指標驅動開發到如何進行偵錯。