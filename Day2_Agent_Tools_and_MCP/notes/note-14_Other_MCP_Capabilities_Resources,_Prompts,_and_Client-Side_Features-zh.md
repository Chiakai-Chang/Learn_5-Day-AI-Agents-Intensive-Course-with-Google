```markdown
### 🎙️ 第 14 頁：Other MCP Capabilities: Resources, Prompts, and Client-Side Features

#### 【本頁重點摘要】
*   MCP 除了核心的 `Tools` 之外，還定義了其他五種進階但採用率較低的功能。
*   伺服器端功能 (`Resources`, `Prompts`) 讓伺服器能提供額外的資料和指令模板。
*   用戶端功能 (`Sampling`, `Elicitation`) 顛倒了控制流程，允許伺服器向用戶端請求 LLM 運算或使用者輸入。
*   每一項進階功能都伴隨著顯著的資安風險，例如提示詞注入 (Prompt Injection) 或敏感資訊洩露。

---

#### 【逐字講稿】

(開場白)
好的，我們剛剛已經深入了解了 MCP 的核心——也就是「工具 (Tools)」。但其實，MCP 的設計藍圖遠比這更宏大。它還定義了一些更進階、也更具實驗性的功能。這些功能雖然目前還不普及，但它們像一扇窗，讓我們窺見 MCP 未來的潛力...以及，與之相伴的巨大風險。

##### ① 伺服器端的野心：`Resources` 與 `Prompts`

首先，我們來看兩種由「伺服器」提供給「用戶端」的功能。

第一個是 **Resources (資源)**。你可以把它想像成，伺服器除了提供工具外，還能直接提供上下文資料，比如一個 PDF 檔案、一個資料庫紀錄、甚至是設定檔。這聽起來很方便，對吧？但風險也隨之而來。

> 正如我們的原始資料所警告的：從不受信任的來源取用資源，會為系統帶來嚴重的安全漏洞。任何用戶端在取用資源前，都必須進行驗證。

第二個是 **Prompts (提示詞)**。這個功能更進取，它允許伺服器直接提供「提示詞模板」，建議用戶端的 LLM 該如何使用它的工具。這等於是讓工具的開發者，可以教你的 AI 如何思考。但這也打開了潘朵拉的盒子。

> 風險非常明確：這允許了第三方服務，將「任意指令」注入到你的應用程式執行路徑中。這就是典型的**提示詞注入攻擊**。因此，我們的研究建議是，在有更強的資安模型出現之前，這個功能應該「極少使用，甚至完全不要使用」。

##### ② 控制權反轉：`Sampling` 與 `Elicitation`

接下來這兩種功能更有趣，它們將控制權從用戶端「反轉」回伺服器。

第一個是 **Sampling (取樣)**。它允許「伺服器」反過來請求「用戶端」的 LLM 進行一次運算。舉例來說，一個工具在抓取了一份很長的文件後，可以發起 Sampling 請求，要求用戶端的 AI 幫忙「總結這份文件」。這讓伺服器可以利用宿主應⽤程式的核⼼ AI 模型。但風險依然是...**提示詞注入**。如果用戶端沒有過濾這個請求，惡意伺服器就可能藉此操控你的 LLM。

第二個是 **Elicitation (引出)**。這個功能允許伺服器在運作中途暫停，並透過用戶端的介面，直接向「真人使用者」請求更多資訊。這聽起來像是個負責任的互動機制，但卻可能是個陷阱。

> MCP 規範明確指出「伺服器**絕不能**使用此功能請求敏感資訊」。但我們的研究報告也一針見血地指出，這條規則「在系統上是無法強制執行的」。一個惡意伺服器，可以輕易地利用這個功能，誘騙使用者洩漏敏感個資。

##### ③ 模糊的邊界：`Roots`

最後一個是 **Roots (根目錄)**。它的設計初衷是好的，用來定義伺服器可以在哪個檔案系統範圍內運作，就像一個沙盒。但它的約束力非常薄弱。

> 規範裡用的詞是，伺服器「**應該 (SHOULD)**」尊重這個邊界，而不是「**必須 (MUST)**」。在資安領域，這是一個巨大的警訊。這意味著它只是一個君子協定，任何開發者都不應該過度信賴它。

---

#### 【講者提示 & 轉場】
*   **節奏提醒**：講到每一項功能的風險時，可以加重語氣，讓聽眾感受到「能力」與「風險」之間的緊張關係。這些功能就像是軟體裡的「開發者模式」，功能強大，但也非常危險。
*   **核心觀點**：強調這些功能雖然採用率低，但它們展示了 MCP 試圖標準化「AI 之間複雜互動」的雄心。
*   **轉場橋樑 (Bridge)**：
    > 看到這裡，大家可能會想，既然有這麼多潛在的風險，我們為什麼還要關注 MCP 呢？這是一個非常好的問題。因為，如果我們能妥善管理這些風險，MCP 所帶來的正面效益——也就是我們接下來要談的「加速開發」和「建立可重複使用的生態系」——將是無比巨大的。